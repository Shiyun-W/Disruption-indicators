{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 6: Distributions of ranks of scientific breakthroughs in the PubMed dataset for the five disruption indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mED(rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Science breakthrough papers\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "test = pd.read_csv(r'data/test_dataset_science.csv', header = 0)    # including pmid, pub_year\n",
    "pubmed_mED_rel = pd.read_csv(r'data/pubmed_mED(rel).csv', header = 0)    # including pmid, pub_year, mED_rel\n",
    "\n",
    "ranks_mED_rel_science = []\n",
    "\n",
    "for y in range(1991, 2015):\n",
    "    pubmed_year = pubmed_mED_rel[pubmed_mED_rel['pub_year'] == y]\n",
    "    pubmed_year.sort_values('mED_rel', ascending = False, inplace = True, ignore_index = True)\n",
    "    \n",
    "    test_year = list(test[test['pub_year'] == y]['pmid'].values)\n",
    "    hit_papers_df = pubmed_year[pubmed_year.pmid.isin(test_year)]\n",
    "    hit_papers_ranks = list(hit_papers_df.index.values)\n",
    "    ranks_mED_rel_science.extend([i+1 for i in hit_papers_ranks])\n",
    "    \n",
    "print(len(ranks_mED_rel_science))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prize papers\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "test = pd.read_csv(r'data/test_dataset_prize.csv', header = 0)\n",
    "pubmed_mED_rel = pd.read_csv(r'data/pubmed_mED(rel).csv', header = 0)\n",
    "\n",
    "ranks_mED_rel_prize = []\n",
    "\n",
    "for y in range(1991, 2015):\n",
    "    pubmed_year = pubmed_mED_rel[pubmed_mED_rel['pub_year'] == y]\n",
    "    pubmed_year.sort_values('mED_rel', ascending = False, inplace = True, ignore_index = True)\n",
    "    \n",
    "    test_year = list(test[test['pub_year'] == y]['pmid'].values)\n",
    "    hit_papers_df = pubmed_year[pubmed_year.pmid.isin(test_year)]\n",
    "    hit_papers_ranks = list(hit_papers_df.index.values)\n",
    "    ranks_mED_rel_prize.extend([i+1 for i in hit_papers_ranks])\n",
    "    \n",
    "print(len(ranks_mED_rel_prize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highly cited papers\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "test = pd.read_csv(r'data/test_dataset_highly_cited.csv', header = 0)\n",
    "pubmed_mED_rel = pd.read_csv(r'data/pubmed_mED(rel).csv', header = 0)\n",
    "\n",
    "ranks_mED_rel_highly_cited = []\n",
    "\n",
    "for y in range(1991, 2015):\n",
    "    pubmed_year = pubmed_mED_rel[pubmed_mED_rel['pub_year'] == y]\n",
    "    pubmed_year.sort_values('mED_rel', ascending = False, inplace = True, ignore_index = True)\n",
    "    \n",
    "    test_year = list(test[test['pub_year'] == y]['pmid'].values)\n",
    "    hit_papers_df = pubmed_year[pubmed_year.pmid.isin(test_year)]\n",
    "    hit_papers_ranks = list(hit_papers_df.index.values)\n",
    "    ranks_mED_rel_highly_cited.extend([i+1 for i in hit_papers_ranks])\n",
    "    \n",
    "print(len(ranks_mED_rel_highly_cited))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faculty papers\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "test = pd.read_csv(r'data/test_dataset_faculty.csv', header = 0)\n",
    "pubmed_mED_rel = pd.read_csv(r'data/pubmed_mED(rel).csv', header = 0)\n",
    "\n",
    "ranks_mED_rel_faculty = []\n",
    "\n",
    "for y in range(1991, 2015):\n",
    "    pubmed_year = pubmed_mED_rel[pubmed_mED_rel['pub_year'] == y]\n",
    "    pubmed_year.sort_values('mED_rel', ascending = False, inplace = True, ignore_index = True)\n",
    "    \n",
    "    test_year = list(test[test['pub_year'] == y]['pmid'].values)\n",
    "    hit_papers_df = pubmed_year[pubmed_year.pmid.isin(test_year)]\n",
    "    hit_papers_ranks = list(hit_papers_df.index.values)\n",
    "    ranks_mED_rel_faculty.extend([i+1 for i in hit_papers_ranks])\n",
    "    \n",
    "print(len(ranks_mED_rel_faculty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "bins = 100\n",
    "fig, ax = plt.subplots(1,4, figsize = (18, 4.5))\n",
    "\n",
    "data = [ranks_mED_rel_science, ranks_mED_rel_prize, ranks_mED_rel_highly_cited, ranks_mED_rel_faculty]\n",
    "\n",
    "color_list = ['#8EA3C2', '#A3B38C', '#EDB17F', '#b3b8bc']\n",
    "titles = ['Science breakthrough papers', 'Prize papers', 'Highly cited papers', 'Faculty Opinions papers']\n",
    "\n",
    "for x in range(4):\n",
    "    sns.kdeplot(data[x],ax = ax[x], shade = True, color = color_list[x], alpha = 0.5)\n",
    "    rank_mean = np.mean(data[x])\n",
    "    ax[x].axvline(x = rank_mean, linestyle = '--', color = 'gray')\n",
    "    if x != 3:\n",
    "        ax[x].text(x = 0.18, y = 0.7, s = 'higher\\ndisruption', fontsize = 12, horizontalalignment = 'center', verticalalignment = 'center', transform = ax[x].transAxes)\n",
    "        ax[x].text(x = 0.6, y = 0.7, s = 'lower\\ndisruption', fontsize = 12, horizontalalignment = 'center', verticalalignment = 'center', transform = ax[x].transAxes)\n",
    "    else:\n",
    "        ax[x].text(x = 0.18, y = 0.7, s = 'higher\\ndisruption', fontsize = 12, horizontalalignment = 'center', verticalalignment = 'center', transform = ax[x].transAxes)\n",
    "        ax[x].text(x = 0.6, y = 0.7, s = 'lower\\ndisruption', fontsize = 12, horizontalalignment = 'center', verticalalignment = 'center', transform = ax[x].transAxes)\n",
    "    ax[x].set_xlabel('Rankings', fontsize = 12)\n",
    "    ax[x].tick_params(axis = 'x',labelsize = 12, labelrotation = 20)\n",
    "    ax[x].tick_params(axis = 'y', labelsize = 12)\n",
    "    ax[x].spines['bottom'].set_linewidth(0.5)\n",
    "    ax[x].spines['bottom'].set_color('black')\n",
    "    ax[x].spines['left'].set_linewidth(0.5)\n",
    "    ax[x].spines['left'].set_color('black')\n",
    "    ax[x].spines['top'].set_linewidth(0.5)\n",
    "    ax[x].spines['top'].set_color('black')\n",
    "    ax[x].spines['right'].set_linewidth(0.5)\n",
    "    ax[x].spines['right'].set_color('black')\n",
    "    ax[x].spines['right'].set_visible(False)\n",
    "    ax[x].spines['top'].set_visible(False)\n",
    "    ax[x].set_title(titles[x], fontsize = 12, fontweight = 'medium')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('(a) mED(rel)', fontsize = 14, ha = 'left',va = 'top', fontweight = 'bold', x = 0.002, y = 0.9999)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mED(ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Science breakthrough papers\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "test = pd.read_csv(r'data/test_dataset_science.csv', header = 0)\n",
    "pubmed_mED_ent = pd.read_csv(r'data/pubmed_mED(ent).csv', header = 0)\n",
    "\n",
    "ranks_mED_ent_science = []\n",
    "\n",
    "for y in range(1991, 2015):\n",
    "    pubmed_year = pubmed_mED_ent[pubmed_mED_ent['pub_year'] == y]\n",
    "    pubmed_year.sort_values('mED_ent', ascending = False, inplace = True, ignore_index = True)\n",
    "    \n",
    "    test_year = list(test[test['pub_year'] == y]['pmid'].values)\n",
    "    hit_papers_df = pubmed_year[pubmed_year.pmid.isin(test_year)]\n",
    "    hit_papers_ranks = list(hit_papers_df.index.values)\n",
    "    ranks_mED_ent_science.extend([i+1 for i in hit_papers_ranks])\n",
    "    \n",
    "print(len(ranks_mED_ent_science))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prize papers\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "test = pd.read_csv(r'data/test_dataset_prize.csv', header = 0)\n",
    "pubmed_mED_ent = pd.read_csv(r'data/pubmed_mED(ent).csv', header = 0)\n",
    "\n",
    "ranks_mED_ent_prize = []\n",
    "\n",
    "for y in range(1991, 2015):\n",
    "    pubmed_year = pubmed_mED_ent[pubmed_mED_ent['pub_year'] == y]\n",
    "    pubmed_year.sort_values('mED_ent', ascending = False, inplace = True, ignore_index = True)\n",
    "    \n",
    "    test_year = list(test[test['pub_year'] == y]['pmid'].values)\n",
    "    hit_papers_df = pubmed_year[pubmed_year.pmid.isin(test_year)]\n",
    "    hit_papers_ranks = list(hit_papers_df.index.values)\n",
    "    ranks_mED_ent_prize.extend([i+1 for i in hit_papers_ranks])\n",
    "    \n",
    "print(len(ranks_mED_ent_prize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highly cited papers\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "test = pd.read_csv(r'data/test_dataset_highly_cited.csv', header = 0)\n",
    "pubmed_mED_ent = pd.read_csv(r'data/pubmed_mED(ent).csv', header = 0)\n",
    "\n",
    "ranks_mED_ent_highly_cited = []\n",
    "\n",
    "for y in range(1991, 2015):\n",
    "    pubmed_year = pubmed_mED_ent[pubmed_mED_ent['pub_year'] == y]\n",
    "    pubmed_year.sort_values('mED_ent', ascending = False, inplace = True, ignore_index = True)\n",
    "    \n",
    "    test_year = list(test[test['pub_year'] == y]['pmid'].values)\n",
    "    hit_papers_df = pubmed_year[pubmed_year.pmid.isin(test_year)]\n",
    "    hit_papers_ranks = list(hit_papers_df.index.values)\n",
    "    ranks_mED_ent_highly_cited.extend([i+1 for i in hit_papers_ranks])\n",
    "    \n",
    "print(len(ranks_mED_ent_highly_cited))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faculty papers\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "test = pd.read_csv(r'data/test_dataset_faculty.csv', header = 0)\n",
    "pubmed_mED_ent = pd.read_csv(r'data/pubmed_mED(ent).csv', header = 0)\n",
    "\n",
    "ranks_mED_ent_faculty = []\n",
    "\n",
    "for y in range(1991, 2015):\n",
    "    pubmed_year = pubmed_mED_ent[pubmed_mED_ent['pub_year'] == y]\n",
    "    pubmed_year.sort_values('mED_ent', ascending = False, inplace = True, ignore_index = True)\n",
    "    \n",
    "    test_year = list(test[test['pub_year'] == y]['pmid'].values)\n",
    "    hit_papers_df = pubmed_year[pubmed_year.pmid.isin(test_year)]\n",
    "    hit_papers_ranks = list(hit_papers_df.index.values)\n",
    "    ranks_mED_ent_faculty.extend([i+1 for i in hit_papers_ranks])\n",
    "    \n",
    "print(len(ranks_mED_ent_faculty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "bins = 100\n",
    "fig, ax = plt.subplots(1,4, figsize = (18, 4.5))\n",
    "\n",
    "data = [ranks_mED_ent_science, ranks_mED_ent_prize, ranks_mED_ent_highly_cited, ranks_mED_ent_faculty]\n",
    "\n",
    "color_list = ['#8EA3C2', '#A3B38C', '#EDB17F', '#b3b8bc']\n",
    "titles = ['Science breakthrough papers', 'Prize papers', 'Highly cited papers', 'Faculty Opinions papers']\n",
    "\n",
    "for x in range(4):\n",
    "    sns.kdeplot(data[x],ax = ax[x], shade = True, color = color_list[x], alpha = 0.5)\n",
    "    rank_mean = np.mean(data[x])\n",
    "    ax[x].axvline(x = rank_mean, linestyle = '--', color = 'gray')\n",
    "    if x != 3:\n",
    "        ax[x].text(x = 0.3, y = 0.7, s = 'higher\\ndisruption', fontsize = 12, horizontalalignment = 'center', verticalalignment = 'center', transform = ax[x].transAxes)\n",
    "        ax[x].text(x = 0.8, y = 0.7, s = 'lower\\ndisruption', fontsize = 12, horizontalalignment = 'center', verticalalignment = 'center', transform = ax[x].transAxes)\n",
    "    else:\n",
    "        ax[x].text(x = 0.4, y = 0.7, s = 'higher\\ndisruption', fontsize = 12, horizontalalignment = 'center', verticalalignment = 'center', transform = ax[x].transAxes)\n",
    "        ax[x].text(x = 0.9, y = 0.7, s = 'lower\\ndisruption', fontsize = 12, horizontalalignment = 'center', verticalalignment = 'center', transform = ax[x].transAxes)\n",
    "    ax[x].set_xlabel('Rankings', fontsize = 12)\n",
    "    ax[x].tick_params(axis = 'x',labelsize = 12, labelrotation = 20)\n",
    "    ax[x].tick_params(axis = 'y', labelsize = 12)\n",
    "    ax[x].spines['bottom'].set_linewidth(0.5)\n",
    "    ax[x].spines['bottom'].set_color('black')\n",
    "    ax[x].spines['left'].set_linewidth(0.5)\n",
    "    ax[x].spines['left'].set_color('black')\n",
    "    ax[x].spines['top'].set_linewidth(0.5)\n",
    "    ax[x].spines['top'].set_color('black')\n",
    "    ax[x].spines['right'].set_linewidth(0.5)\n",
    "    ax[x].spines['right'].set_color('black')\n",
    "    ax[x].spines['right'].set_visible(False)\n",
    "    ax[x].spines['top'].set_visible(False)\n",
    "    ax[x].set_title(titles[x], fontsize = 12, fontweight = 'medium')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('(b) mED(ent)', fontsize = 14, ha = 'left',va = 'top', fontweight = 'bold', x = 0.002, y = 0.9999)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Science breakthrough papers\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "test = pd.read_csv(r'data/test_dataset_science.csv', header = 0)\n",
    "pubmed_mCD = pd.read_csv(r'data/pubmed_mCD.csv', header = 0)\n",
    "\n",
    "ranks_mCD_science = []\n",
    "\n",
    "for y in range(1991, 2015):\n",
    "    pubmed_year = pubmed_mCD[pubmed_mCD['pub_year'] == y]\n",
    "    pubmed_year.sort_values('mCD', ascending = False, inplace = True, ignore_index = True)\n",
    "    \n",
    "    test_year = list(test[test['pub_year'] == y]['pmid'].values)\n",
    "    hit_papers_df = pubmed_year[pubmed_year.pmid.isin(test_year)]\n",
    "    hit_papers_ranks = list(hit_papers_df.index.values)\n",
    "    ranks_mCD_science.extend([i+1 for i in hit_papers_ranks])\n",
    "    \n",
    "print(len(ranks_mCD_science))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prize papers\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "test = pd.read_csv(r'data/test_dataset_prize.csv', header = 0)\n",
    "pubmed_mCD = pd.read_csv(r'data/pubmed_mCD.csv', header = 0)\n",
    "\n",
    "ranks_mCD_prize = []\n",
    "\n",
    "for y in range(1991, 2015):\n",
    "    pubmed_year = pubmed_mCD[pubmed_mCD['pub_year'] == y]\n",
    "    pubmed_year.sort_values('mCD', ascending = False, inplace = True, ignore_index = True)\n",
    "    \n",
    "    test_year = list(test[test['pub_year'] == y]['pmid'].values)\n",
    "    hit_papers_df = pubmed_year[pubmed_year.pmid.isin(test_year)]\n",
    "    hit_papers_ranks = list(hit_papers_df.index.values)\n",
    "    ranks_mCD_prize.extend([i+1 for i in hit_papers_ranks])\n",
    "    \n",
    "print(len(ranks_mCD_prize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highly cited papers\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "test = pd.read_csv(r'data/test_dataset_highly_cited.csv', header = 0)\n",
    "pubmed_mCD = pd.read_csv(r'data/pubmed_mCD.csv', header = 0)\n",
    "\n",
    "ranks_mCD_highly_cited = []\n",
    "\n",
    "for y in range(1991, 2015):\n",
    "    pubmed_year = pubmed_mCD[pubmed_mCD['pub_year'] == y]\n",
    "    pubmed_year.sort_values('mCD', ascending = False, inplace = True, ignore_index = True)\n",
    "    \n",
    "    test_year = list(test[test['pub_year'] == y]['pmid'].values)\n",
    "    hit_papers_df = pubmed_year[pubmed_year.pmid.isin(test_year)]\n",
    "    hit_papers_ranks = list(hit_papers_df.index.values)\n",
    "    ranks_mCD_highly_cited.extend([i+1 for i in hit_papers_ranks])\n",
    "    \n",
    "print(len(ranks_mCD_highly_cited))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faculty papers\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "test = pd.read_csv(r'data/test_dataset_faculty.csv', header = 0)\n",
    "pubmed_mCD = pd.read_csv(r'data/pubmed_mCD.csv', header = 0)\n",
    "\n",
    "ranks_mCD_faculty = []\n",
    "\n",
    "for y in range(1991, 2015):\n",
    "    pubmed_year = pubmed_mCD[pubmed_mCD['pub_year'] == y]\n",
    "    pubmed_year.sort_values('mCD', ascending = False, inplace = True, ignore_index = True)\n",
    "    \n",
    "    test_year = list(test[test['pub_year'] == y]['pmid'].values)\n",
    "    hit_papers_df = pubmed_year[pubmed_year.pmid.isin(test_year)]\n",
    "    hit_papers_ranks = list(hit_papers_df.index.values)\n",
    "    ranks_mCD_faculty.extend([i+1 for i in hit_papers_ranks])\n",
    "    \n",
    "print(len(ranks_mCD_faculty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "bins = 100\n",
    "fig, ax = plt.subplots(1,4, figsize = (18, 4.5))\n",
    "\n",
    "data = [ranks_mCD_science, ranks_mCD_prize, ranks_mCD_highly_cited, ranks_mCD_faculty]\n",
    "\n",
    "color_list = ['#8EA3C2', '#A3B38C', '#EDB17F', '#b3b8bc']\n",
    "titles = ['Science breakthrough papers', 'Prize papers', 'Highly cited papers', 'Faculty Opinions papers']\n",
    "\n",
    "for x in range(4):\n",
    "    sns.kdeplot(data[x],ax = ax[x], shade = True, color = color_list[x], alpha = 0.5)\n",
    "    rank_mean = np.mean(data[x])\n",
    "    ax[x].axvline(x = rank_mean, linestyle = '--', color = 'gray')\n",
    "    if x != 3:\n",
    "        ax[x].text(x = 0.25, y = 0.7, s = 'higher\\ndisruption', fontsize = 12, horizontalalignment = 'center', verticalalignment = 'center', transform = ax[x].transAxes)\n",
    "        ax[x].text(x = 0.7, y = 0.7, s = 'lower\\ndisruption', fontsize = 12, horizontalalignment = 'center', verticalalignment = 'center', transform = ax[x].transAxes)\n",
    "    else:\n",
    "        ax[x].text(x = 0.3, y = 0.7, s = 'higher\\ndisruption', fontsize = 12, horizontalalignment = 'center', verticalalignment = 'center', transform = ax[x].transAxes)\n",
    "        ax[x].text(x = 0.85, y = 0.7, s = 'lower\\ndisruption', fontsize = 12, horizontalalignment = 'center', verticalalignment = 'center', transform = ax[x].transAxes)\n",
    "    ax[x].set_xlabel('Rankings', fontsize = 12)\n",
    "    ax[x].tick_params(axis = 'x',labelsize = 12, labelrotation = 20)\n",
    "    ax[x].tick_params(axis = 'y', labelsize = 12)\n",
    "    ax[x].spines['bottom'].set_linewidth(0.5)\n",
    "    ax[x].spines['bottom'].set_color('black')\n",
    "    ax[x].spines['left'].set_linewidth(0.5)\n",
    "    ax[x].spines['left'].set_color('black')\n",
    "    ax[x].spines['top'].set_linewidth(0.5)\n",
    "    ax[x].spines['top'].set_color('black')\n",
    "    ax[x].spines['right'].set_linewidth(0.5)\n",
    "    ax[x].spines['right'].set_color('black')\n",
    "    ax[x].spines['right'].set_visible(False)\n",
    "    ax[x].spines['top'].set_visible(False)\n",
    "    ax[x].set_title(titles[x], fontsize = 12, fontweight = 'medium')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('(c) mCD', fontsize = 14, ha = 'left',va = 'top', fontweight = 'bold', x = 0.002, y = 0.9999)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DI5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Science breakthrough papers\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "test = pd.read_csv(r'data/test_dataset_science.csv', header = 0)\n",
    "pubmed_di5 = pd.read_csv(r'data/pubmed_di5.csv', header = 0)\n",
    "\n",
    "ranks_di5_science = []\n",
    "\n",
    "for y in range(1991, 2015):\n",
    "    pubmed_year = pubmed_di5[pubmed_di5['pub_year'] == y]\n",
    "    pubmed_year.sort_values('DI5', ascending = False, inplace = True, ignore_index = True)\n",
    "    \n",
    "    test_year = list(test[test['pub_year'] == y]['pmid'].values)\n",
    "    hit_papers_df = pubmed_year[pubmed_year.pmid.isin(test_year)]\n",
    "    hit_papers_ranks = list(hit_papers_df.index.values)\n",
    "    ranks_di5_science.extend([i+1 for i in hit_papers_ranks])\n",
    "    \n",
    "print(len(ranks_di5_science))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prize papers\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "test = pd.read_csv(r'data/test_dataset_prize.csv', header = 0)\n",
    "pubmed_di5 = pd.read_csv(r'data/pubmed_di5.csv', header = 0)\n",
    "\n",
    "ranks_di5_prize = []\n",
    "\n",
    "for y in range(1991, 2015):\n",
    "    pubmed_year = pubmed_di5[pubmed_di5['pub_year'] == y]\n",
    "    pubmed_year.sort_values('DI5', ascending = False, inplace = True, ignore_index = True)\n",
    "    \n",
    "    test_year = list(test[test['pub_year'] == y]['pmid'].values)\n",
    "    hit_papers_df = pubmed_year[pubmed_year.pmid.isin(test_year)]\n",
    "    hit_papers_ranks = list(hit_papers_df.index.values)\n",
    "    ranks_di5_prize.extend([i+1 for i in hit_papers_ranks])\n",
    "    \n",
    "print(len(ranks_di5_prize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highly cited papers\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "test = pd.read_csv(r'data/test_dataset_highly_cited.csv', header = 0)\n",
    "pubmed_di5 = pd.read_csv(r'data/pubmed_di5.csv', header = 0)\n",
    "\n",
    "ranks_di5_highly_cited = []\n",
    "\n",
    "for y in range(1991, 2015):\n",
    "    pubmed_year = pubmed_di5[pubmed_di5['pub_year'] == y]\n",
    "    pubmed_year.sort_values('DI5', ascending = False, inplace = True, ignore_index = True)\n",
    "    \n",
    "    test_year = list(test[test['pub_year'] == y]['pmid'].values)\n",
    "    hit_papers_df = pubmed_year[pubmed_year.pmid.isin(test_year)]\n",
    "    hit_papers_ranks = list(hit_papers_df.index.values)\n",
    "    ranks_di5_highly_cited.extend([i+1 for i in hit_papers_ranks])\n",
    "    \n",
    "print(len(ranks_di5_highly_cited))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faculty papers\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "test = pd.read_csv(r'data/test_dataset_faculty.csv', header = 0)\n",
    "pubmed_di5 = pd.read_csv(r'data/pubmed_di5.csv', header = 0)\n",
    "\n",
    "ranks_di5_faculty = []\n",
    "\n",
    "for y in range(1991, 2015):\n",
    "    pubmed_year = pubmed_di5[pubmed_di5['pub_year'] == y]\n",
    "    pubmed_year.sort_values('DI5', ascending = False, inplace = True, ignore_index = True)\n",
    "    \n",
    "    test_year = list(test[test['pub_year'] == y]['pmid'].values)\n",
    "    hit_papers_df = pubmed_year[pubmed_year.pmid.isin(test_year)]\n",
    "    hit_papers_ranks = list(hit_papers_df.index.values)\n",
    "    ranks_di5_faculty.extend([i+1 for i in hit_papers_ranks])\n",
    "    \n",
    "print(len(ranks_di5_faculty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "bins = 100\n",
    "fig, ax = plt.subplots(1,4, figsize = (18, 4.5))\n",
    "\n",
    "data = [ranks_di5_science, ranks_di5_prize, ranks_di5_highly_cited, ranks_di5_faculty]\n",
    "\n",
    "color_list = ['#8EA3C2', '#A3B38C', '#EDB17F', '#b3b8bc']\n",
    "titles = ['Science breakthrough papers', 'Prize papers', 'Highly cited papers', 'Faculty Opinions papers']\n",
    "\n",
    "for x in range(4):\n",
    "    sns.kdeplot(data[x],ax = ax[x], shade = True, color = color_list[x], alpha = 0.5)\n",
    "    rank_mean = np.mean(data[x])\n",
    "    ax[x].axvline(x = rank_mean, linestyle = '--', color = 'gray')\n",
    "    if x != 2:\n",
    "        ax[x].text(x = 0.2, y = 0.7, s = 'higher\\ndisruption', fontsize = 12, horizontalalignment = 'center', verticalalignment = 'center', transform = ax[x].transAxes)\n",
    "        ax[x].text(x = 0.65, y = 0.7, s = 'lower\\ndisruption', fontsize = 12, horizontalalignment = 'center', verticalalignment = 'center', transform = ax[x].transAxes)\n",
    "    else:\n",
    "        ax[x].text(x = 0.12, y = 0.7, s = 'higher\\ndisruption', fontsize = 12, horizontalalignment = 'center', verticalalignment = 'center', transform = ax[x].transAxes)\n",
    "        ax[x].text(x = 0.65, y = 0.7, s = 'lower\\ndisruption', fontsize = 12, horizontalalignment = 'center', verticalalignment = 'center', transform = ax[x].transAxes)\n",
    "    ax[x].set_xlabel('Rankings', fontsize = 12)\n",
    "    ax[x].tick_params(axis = 'x',labelsize = 12, labelrotation = 20)\n",
    "    ax[x].tick_params(axis = 'y', labelsize = 12)\n",
    "    ax[x].spines['bottom'].set_linewidth(0.5)\n",
    "    ax[x].spines['bottom'].set_color('black')\n",
    "    ax[x].spines['left'].set_linewidth(0.5)\n",
    "    ax[x].spines['left'].set_color('black')\n",
    "    ax[x].spines['top'].set_linewidth(0.5)\n",
    "    ax[x].spines['top'].set_color('black')\n",
    "    ax[x].spines['right'].set_linewidth(0.5)\n",
    "    ax[x].spines['right'].set_color('black')\n",
    "    ax[x].spines['right'].set_visible(False)\n",
    "    ax[x].spines['top'].set_visible(False)\n",
    "    ax[x].set_title(titles[x], fontsize = 12, fontweight = 'medium')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('(d) DI5', fontsize = 14, ha = 'left',va = 'top', fontweight = 'bold', x = 0.002, y = 0.9999)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DI1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Science breakthrough papers\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "test = pd.read_csv(r'data/test_dataset_science.csv', header = 0)\n",
    "pubmed_di1 = pd.read_csv(r'data/pubmed_di1.csv', header = 0)\n",
    "\n",
    "ranks_di1_science = []\n",
    "\n",
    "for y in range(1991, 2015):\n",
    "    pubmed_year = pubmed_di1[pubmed_di1['pub_year'] == y]\n",
    "    pubmed_year.sort_values('DI1', ascending = False, inplace = True, ignore_index = True)\n",
    "    \n",
    "    test_year = list(test[test['pub_year'] == y]['pmid'].values)\n",
    "    hit_papers_df = pubmed_year[pubmed_year.pmid.isin(test_year)]\n",
    "    hit_papers_ranks = list(hit_papers_df.index.values)\n",
    "    ranks_di1_science.extend([i+1 for i in hit_papers_ranks])\n",
    "    \n",
    "print(len(ranks_di1_science))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prize papers\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "test = pd.read_csv(r'data/test_dataset_prize.csv', header = 0)\n",
    "pubmed_di1 = pd.read_csv(r'data/pubmed_di1.csv', header = 0)\n",
    "\n",
    "ranks_di1_prize = []\n",
    "\n",
    "for y in range(1991, 2015):\n",
    "    pubmed_year = pubmed_di1[pubmed_di1['pub_year'] == y]\n",
    "    pubmed_year.sort_values('DI1', ascending = False, inplace = True, ignore_index = True)\n",
    "    \n",
    "    test_year = list(test[test['pub_year'] == y]['pmid'].values)\n",
    "    hit_papers_df = pubmed_year[pubmed_year.pmid.isin(test_year)]\n",
    "    hit_papers_ranks = list(hit_papers_df.index.values)\n",
    "    ranks_di1_prize.extend([i+1 for i in hit_papers_ranks])\n",
    "    \n",
    "print(len(ranks_di1_prize))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highly cited papers\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "test = pd.read_csv(r'data/test_dataset_highly_cited.csv', header = 0)\n",
    "pubmed_di1 = pd.read_csv(r'data/pubmed_di1.csv', header = 0)\n",
    "\n",
    "ranks_di1_highly_cited = []\n",
    "\n",
    "for y in range(1991, 2015):\n",
    "    pubmed_year = pubmed_di1[pubmed_di1['pub_year'] == y]\n",
    "    pubmed_year.sort_values('DI1', ascending = False, inplace = True, ignore_index = True)\n",
    "    \n",
    "    test_year = list(test[test['pub_year'] == y]['pmid'].values)\n",
    "    hit_papers_df = pubmed_year[pubmed_year.pmid.isin(test_year)]\n",
    "    hit_papers_ranks = list(hit_papers_df.index.values)\n",
    "    ranks_di1_highly_cited.extend([i+1 for i in hit_papers_ranks])\n",
    "    \n",
    "print(len(ranks_di1_highly_cited))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faculty papers\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "test = pd.read_csv(r'data/test_dataset_faculty.csv', header = 0)\n",
    "pubmed_di1 = pd.read_csv(r'data/pubmed_di1.csv', header = 0)\n",
    "\n",
    "ranks_di1_faculty = []\n",
    "\n",
    "for y in range(1991, 2015):\n",
    "    pubmed_year = pubmed_di1[pubmed_di1['pub_year'] == y]\n",
    "    pubmed_year.sort_values('DI1', ascending = False, inplace = True, ignore_index = True)\n",
    "    \n",
    "    test_year = list(test[test['pub_year'] == y]['pmid'].values)\n",
    "    hit_papers_df = pubmed_year[pubmed_year.pmid.isin(test_year)]\n",
    "    hit_papers_ranks = list(hit_papers_df.index.values)\n",
    "    ranks_di1_faculty.extend([i+1 for i in hit_papers_ranks])\n",
    "    \n",
    "print(len(ranks_di1_faculty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "bins = 100\n",
    "fig, ax = plt.subplots(1,4, figsize = (18, 4.5))\n",
    "\n",
    "data = [ranks_di1_science, ranks_di1_prize, ranks_di1_highly_cited, ranks_di1_faculty]\n",
    "\n",
    "color_list = ['#8EA3C2', '#A3B38C', '#EDB17F', '#b3b8bc']\n",
    "titles = ['Science breakthrough papers', 'Prize papers', 'Highly cited papers', 'Faculty Opinions papers']\n",
    "\n",
    "for x in range(4):\n",
    "    sns.kdeplot(data[x],ax = ax[x], shade = True, color = color_list[x], alpha = 0.5)\n",
    "    rank_mean = np.mean(data[x])\n",
    "    ax[x].axvline(x = rank_mean, linestyle = '--', color = 'gray')\n",
    "    if x != 2:\n",
    "        ax[x].text(x = 0.25, y = 0.7, s = 'higher\\ndisruption', fontsize = 12, horizontalalignment = 'center', verticalalignment = 'center', transform = ax[x].transAxes)\n",
    "        ax[x].text(x = 0.7, y = 0.7, s = 'lower\\ndisruption', fontsize = 12, horizontalalignment = 'center', verticalalignment = 'center', transform = ax[x].transAxes)\n",
    "    else:\n",
    "        ax[x].text(x = 0.25, y = 0.7, s = 'higher\\ndisruption', fontsize = 12, horizontalalignment = 'center', verticalalignment = 'center', transform = ax[x].transAxes)\n",
    "        ax[x].text(x = 0.7, y = 0.7, s = 'lower\\ndisruption', fontsize = 12, horizontalalignment = 'center', verticalalignment = 'center', transform = ax[x].transAxes)\n",
    "    ax[x].set_xlabel('Rankings', fontsize = 12)\n",
    "    ax[x].tick_params(axis = 'x',labelsize = 12, labelrotation = 20)\n",
    "    ax[x].tick_params(axis = 'y', labelsize = 12)\n",
    "    ax[x].spines['bottom'].set_linewidth(0.5)\n",
    "    ax[x].spines['bottom'].set_color('black')\n",
    "    ax[x].spines['left'].set_linewidth(0.5)\n",
    "    ax[x].spines['left'].set_color('black')\n",
    "    ax[x].spines['top'].set_linewidth(0.5)\n",
    "    ax[x].spines['top'].set_color('black')\n",
    "    ax[x].spines['right'].set_linewidth(0.5)\n",
    "    ax[x].spines['right'].set_color('black')\n",
    "    ax[x].spines['right'].set_visible(False)\n",
    "    ax[x].spines['top'].set_visible(False)\n",
    "    ax[x].set_title(titles[x], fontsize = 12, fontweight = 'medium')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('(e) DI1', fontsize = 14, ha = 'left',va = 'top', fontweight = 'bold', x = 0.002, y = 0.9999)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 7: The number of scientific breakthroughs ranked among the annual top 0.1% disruptive papers in PubMed over the five disruption indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "test_dataset_list = ['test_dataset_science', 'test_dataset_prize','test_dataset_highly_cited', 'test_dataset_faculty']\n",
    "\n",
    "pubmed_dataset_list = ['pubmed_mED(rel)', 'pubmed_mED(ent)', 'pubmed_mCD', 'pubmed_di5', 'pubmed_di1']\n",
    "indicators = ['mED_rel', 'mED_ent', 'mCD', 'DI5', 'DI1']\n",
    "\n",
    "hits_list = []\n",
    "\n",
    "for i in range(len(test_dataset_list)):\n",
    "    hits_list_i = []    # number of papers ranked among the annual top 0.1% disruptive papers in PubMed\n",
    "    \n",
    "    test_dataset = test_dataset_list[i]\n",
    "    test = pd.read_csv(r'data/%s.csv'%test_dataset, header = 0)\n",
    "    \n",
    "    for j in range(len(pubmed_dataset_list)):\n",
    "        dataset = pubmed_dataset_list[j]\n",
    "        pubmed = pd.read_csv(r'data/%s.csv'%dataset, header = 0)\n",
    "\n",
    "        hits = []\n",
    "        for y in range(1991, 2015):\n",
    "            pubmed_year = pubmed[pubmed['pub_year'] == y]\n",
    "            pubmed_year.sort_values(str(indicators[j]), ascending = False, inplace = True, ignore_index = True)\n",
    "            pubmed_year_indicator = np.array(pubmed_year[str(indicators[j])].values)\n",
    "            dvalue_year_top = np.percentile(pubmed_year_indicator, 99.9)\n",
    "            pmid_year_top = list(pubmed_year[pubmed_year[str(indicators[j])] >= dvalue_year_top]['pmid'].values)\n",
    "\n",
    "            test_year = test[test['pub_year'] == y]['pmid'].values\n",
    "\n",
    "            hit_papers = list(set(list(pmid_year_top)) & set(list(test_year)))\n",
    "            hits.append(len(hit_papers))\n",
    "\n",
    "        hits_list_i.append(hits)\n",
    "        \n",
    "    hits_list.append(hits_list_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "\n",
    "x = np.arange(4)\n",
    "labels = ['mED(rel)', 'mED(ent)', 'mCD', 'DI5', 'DI1']\n",
    "\n",
    "hit_year_dict_list = []\n",
    "\n",
    "for i in range(len(x)):    # four test datasets\n",
    "    hit_year_dict = {}\n",
    "    for y in range(24):\n",
    "        ylist = []\n",
    "        ylist.append(hits_list[i][0][y])\n",
    "        ylist.append(hits_list[i][1][y])\n",
    "        ylist.append(hits_list[i][2][y])\n",
    "        ylist.append(hits_list[i][3][y])\n",
    "        ylist.append(hits_list[i][4][y])\n",
    "        hit_year_dict[y] = ylist\n",
    "    hit_year_dict_list.append(hit_year_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "from matplotlib.colors import ListedColormap\n",
    " \n",
    "fig, ax = plt.subplots(1,4,figsize = (18,4.5))\n",
    "fig.subplots_adjust(top=0.8)\n",
    "\n",
    "cmap = sns.diverging_palette(220, 20, as_cmap=True)\n",
    "\n",
    "x = np.arange(5)     # x-axis scale: five indicators\n",
    "title_list = ['Science breakthrough papers', 'Prize papers', 'Highly cited papers', 'Faculty Opinions papers']\n",
    "labels = ['mED(rel)', 'mED(ent)', 'mCD', 'DI5', 'DI1']\n",
    "width = 0.4\n",
    "\n",
    "for a in range(4):\n",
    "    bottom = np.array([0,0,0,0,0])\n",
    "    colors = cmap(np.linspace(0,1,24))\n",
    "    for y in range(24):\n",
    "        ax[a].bar(x, hit_year_dict_list[a][y], width = width, bottom = bottom, color = colors[y], alpha = 0.8)\n",
    "        bottom =  bottom + np.array(hit_year_dict_list[a][y])\n",
    "\n",
    "    ax[a].set_xticks(x)\n",
    "    ax[a].set_xticklabels(labels, rotation = 30)\n",
    "    ax[a].set_title(str(title_list[a]), fontsize = 14)\n",
    "    ax[a].yaxis.grid(linewidth=0.3,color='gray')\n",
    "    ax[a].set_axisbelow(True)\n",
    "    ax[a].tick_params(labelsize = 14)\n",
    "#     ax[a].spines['bottom'].set_visible(False)\n",
    "#     ax[a].spines['left'].set_visible(False)\n",
    "    ax[a].spines['top'].set_visible(False)\n",
    "    ax[a].spines['right'].set_visible(False)\n",
    "    ax[a].spines['bottom'].set_linewidth(0.5)\n",
    "#     ax[a].spines['bottom'].set_color('black')\n",
    "    ax[a].spines['left'].set_linewidth(0.5)\n",
    "#     ax[a].spines['left'].set_color('black')\n",
    "#     ax[a].spines['top'].set_linewidth(0.5)\n",
    "#     ax[a].spines['top'].set_color('gray')\n",
    "#     ax[a].spines['right'].set_linewidth(0.2)\n",
    "#     ax[a].spines['right'].set_color('gray')\n",
    "\n",
    "ax[0].set_ylabel('Number of hit breakthrough papers', fontsize = 14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table 3: The AUC scores of the five disruption indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUC scores for control groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Science breakthrough papers\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "with open(r'data/control_groups/control_pair_dict_year_authors_and_cits_1to5_science.dat', 'rb') as handle:\n",
    "    control_dict = pickle.load(handle)    # control_dict: key: pmids for Science breakthrough papers, values: list of control papers corresponding to each Science breakthrough paper\n",
    "# print(len(control_dict.keys()))\n",
    "\n",
    "df_pubmed = pd.read_csv(r'data/pubmed_mED(rel).csv', header = 0)    # the path of pubmed dataset can be changed into \"data/pubmed_mED(rel).csv\", \"data/pubmed_mCD.csv\", \"data/pubmed_di5.csv\", and \"data/pubmed_di1.csv\"\n",
    "df_test = df_pubmed[df_pubmed.pmid.isin(list(control_dict.keys()))]\n",
    "\n",
    "n1 = 0\n",
    "n2 = 0\n",
    "\n",
    "for i, item in df_test.iterrows():\n",
    "    test_pmid = item['pmid']\n",
    "    control_pmid = control_dict[test_pmid]\n",
    "    D_test_i = list(df_pubmed[df_pubmed['pmid'] == test_pmid]['mED_rel'].values)[0]\n",
    "    D_control_list = list(df_pubmed[df_pubmed.pmid.isin(control_pmid)]['mED_rel'].values)\n",
    "    for k in D_control_list:\n",
    "        if D_test_i > k:\n",
    "            n1 += 1\n",
    "        elif D_test_i == k:\n",
    "            n2 += 1     \n",
    "\n",
    "AUC_science = round((n1 + 0.5*n2) / (len(df_test) * 5), 8)\n",
    "print(len(df_test)*5)\n",
    "print(n1)\n",
    "print(n2)\n",
    "print(AUC_science)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Prize papers\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "with open(r'data/control_groups/control_pair_dict_year_authors_and_cits_1to5_prize.dat', 'rb') as handle:\n",
    "    control_dict2 = pickle.load(handle)\n",
    "print(len(control_dict2.keys()))\n",
    "\n",
    "df_pubmed = pd.read_csv(r'data/pubmed_mED(rel).csv', header = 0)\n",
    "df_test = df_pubmed[df_pubmed.pmid.isin(list(control_dict2.keys()))]\n",
    "\n",
    "n1 = 0\n",
    "n2 = 0\n",
    "\n",
    "for i, item in df_test.iterrows():\n",
    "    test_pmid = item['pmid']\n",
    "    control_pmid = control_dict2[test_pmid]\n",
    "    D_test_i = list(df_pubmed[df_pubmed['pmid'] == test_pmid]['mED_rel'].values)[0]\n",
    "    D_control_list = list(df_pubmed[df_pubmed.pmid.isin(control_pmid)]['mED_rel'].values)\n",
    "    for k in D_control_list:\n",
    "        if D_test_i > k:\n",
    "            n1 += 1\n",
    "        elif D_test_i == k:\n",
    "            n2 += 1     \n",
    "\n",
    "AUC_prize = round((n1 + 0.5*n2) / (len(df_test) * 5), 8)\n",
    "print(len(df_test)*5)\n",
    "print(n1)\n",
    "print(n2)\n",
    "print(AUC_prize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Highly cited papers\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "with open(r'data/control_groups/control_pair_dict_year_authors_and_1to5_highly_cited.dat', 'rb') as handle:\n",
    "    control_dict3 = pickle.load(handle)\n",
    "print(len(control_dict3.keys()))\n",
    "\n",
    "df_pubmed = pd.read_csv(r'data/pubmed_mED(rel).csv', header = 0)\n",
    "df_test = df_pubmed[df_pubmed.pmid.isin(list(control_dict3.keys()))]\n",
    "\n",
    "n1 = 0\n",
    "n2 = 0\n",
    "\n",
    "for i, item in df_test.iterrows():\n",
    "    test_pmid = item['pmid']\n",
    "    control_pmid = control_dict3[test_pmid]\n",
    "    D_test_i = list(df_pubmed[df_pubmed['pmid'] == test_pmid]['mED_rel'].values)[0]\n",
    "    D_control_list = list(df_pubmed[df_pubmed.pmid.isin(control_pmid)]['mED_rel'].values)\n",
    "    for k in D_control_list:\n",
    "        if D_test_i > k:\n",
    "            n1 += 1\n",
    "        elif D_test_i == k:\n",
    "            n2 += 1     \n",
    "\n",
    "AUC_highly_cited = round((n1 + 0.5*n2) / (len(df_test) * 5), 8)\n",
    "print(len(df_test)*5)\n",
    "print(n1)\n",
    "print(n2)\n",
    "print(AUC_highly_cited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Faculty papers\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "with open(r'data/control_groups/control_pair_dict_year_authors_and_cits_1to5_faculty.dat', 'rb') as handle:\n",
    "    control_dict4 = pickle.load(handle)\n",
    "print(len(control_dict4.keys()))\n",
    "\n",
    "df_pubmed = pd.read_csv(r'data/pubmed_mED(rel).csv', header = 0)\n",
    "df_test = df_pubmed[df_pubmed.pmid.isin(list(control_dict4.keys()))]\n",
    "\n",
    "n1 = 0\n",
    "n2 = 0\n",
    "\n",
    "for i, item in df_test.iterrows():\n",
    "    test_pmid = item['pmid']\n",
    "    control_pmid = control_dict4[test_pmid]\n",
    "    D_test_i = list(df_pubmed[df_pubmed['pmid'] == test_pmid]['mED_rel'].values)[0]\n",
    "    D_control_list = list(df_pubmed[df_pubmed.pmid.isin(control_pmid)]['mED_rel'].values)\n",
    "    for k in D_control_list:\n",
    "        if D_test_i > k:\n",
    "            n1 += 1\n",
    "        elif D_test_i == k:\n",
    "            n2 += 1     \n",
    "\n",
    "AUC_faculty = round((n1 + 0.5*n2) / (len(df_test) * 5), 8)\n",
    "print(len(df_test)*5)\n",
    "print(n1)\n",
    "print(n2)\n",
    "print(AUC_faculty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUC scores for random groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(r'data/control_groups/science_control_pmids_list_random.pkl', 'rb') as f:\n",
    "    science_control_pmids_list = pickle.load(f)\n",
    "\n",
    "with open(r'data/control_groups/prize_control_pmids_list_random.pkl', 'rb') as f:\n",
    "    prize_control_pmids_list = pickle.load(f)\n",
    "    \n",
    "with open(r'data/control_groups/highly_cited_control_pmids_list_random.pkl', 'rb') as f:\n",
    "    highly_cited_control_pmids_list = pickle.load(f)\n",
    "\n",
    "with open(r'data/control_groups/faculty_control_pmids_list_random.pkl', 'rb') as f:\n",
    "    faculty_control_pmids_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Science breakthrough papers\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "df_pubmed = pd.read_csv(r'data/pubmed_mED(rel).csv', header = 0)    # the path of pubmed dataset can be changed into \"data/pubmed_mED(rel).csv\", \"data/pubmed_mCD.csv\", \"data/pubmed_di5.csv\", and \"data/pubmed_di1.csv\"\n",
    "\n",
    "n1 = 0\n",
    "n2 = 0\n",
    "\n",
    "for item in science_control_pmids_list:\n",
    "    D_test = list(df_pubmed[df_pubmed['pmid'] == item[0]]['mED_rel'].values)[0]\n",
    "    D_control = list(df_pubmed[df_pubmed['pmid'] == item[1]]['mED_rel'].values)[0]\n",
    "    if D_test > D_control:\n",
    "        n1 += 1\n",
    "    elif D_test == D_control:\n",
    "        n2 += 1  \n",
    "\n",
    "AUC_science_random = round((n1 + 0.5*n2) / 10000, 8)\n",
    "print(n1)\n",
    "print(n2)\n",
    "print(AUC_science_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Prize papers\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "df_pubmed = pd.read_csv(r'data/pubmed_mED(rel).csv', header = 0)\n",
    "\n",
    "n1 = 0\n",
    "n2 = 0\n",
    "\n",
    "for item in prize_control_pmids_list:\n",
    "    D_test = list(df_pubmed[df_pubmed['pmid'] == item[0]]['mED_rel'].values)[0]\n",
    "    D_control = list(df_pubmed[df_pubmed['pmid'] == item[1]]['mED_rel'].values)[0]\n",
    "    if D_test > D_control:\n",
    "        n1 += 1\n",
    "    elif D_test == D_control:\n",
    "        n2 += 1  \n",
    "\n",
    "AUC_prize_random = round((n1 + 0.5*n2) / 10000, 8)\n",
    "print(n1)\n",
    "print(n2)\n",
    "print(AUC_prize_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Highly cited papers\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "df_pubmed = pd.read_csv(r'data/pubmed_mED(rel).csv', header = 0)\n",
    "\n",
    "n1 = 0\n",
    "n2 = 0\n",
    "\n",
    "for item in highly_cited_control_pmids_list:\n",
    "    D_test = list(df_pubmed[df_pubmed['pmid'] == item[0]]['mED_rel'].values)[0]\n",
    "    D_control = list(df_pubmed[df_pubmed['pmid'] == item[1]]['mED_rel'].values)[0]\n",
    "    if D_test > D_control:\n",
    "        n1 += 1\n",
    "    elif D_test == D_control:\n",
    "        n2 += 1  \n",
    "\n",
    "AUC_highly_cited_random = round((n1 + 0.5*n2) / 10000, 8)\n",
    "print(n1)\n",
    "print(n2)\n",
    "print(AUC_highly_cited_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Highly cited papers\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "df_pubmed = pd.read_csv(r'data/pubmed_mED(rel).csv', header = 0)\n",
    "\n",
    "n1 = 0\n",
    "n2 = 0\n",
    "\n",
    "for item in faculty_control_pmids_list:\n",
    "    D_test = list(df_pubmed[df_pubmed['pmid'] == item[0]]['mED_rel'].values)[0]\n",
    "    D_control = list(df_pubmed[df_pubmed['pmid'] == item[1]]['mED_rel'].values)[0]\n",
    "    if D_test > D_control:\n",
    "        n1 += 1\n",
    "    elif D_test == D_control:\n",
    "        n2 += 1  \n",
    "\n",
    "AUC_faculty_random = round((n1 + 0.5*n2) / 10000, 8)\n",
    "print(n1)\n",
    "print(n2)\n",
    "print(AUC_faculty_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 8: Distributions of disruption scores of scientific breakthroughs and control papers for mED(rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Science Breakthrough papers\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "with open('control_groups/control_pair_dict_year_authors_and_cits_1to5_science.dat', 'rb') as handle:\n",
    "    control_dict = pickle.load(handle)\n",
    "print(len(control_dict.keys()))\n",
    "\n",
    "df_pubmed = pd.read_csv(r'data/pubmed_mED(rel).csv', header = 0)\n",
    "df_test = df_pubmed[df_pubmed.pmid.isin(list(control_dict.keys()))]\n",
    "\n",
    "D_test = []\n",
    "D_control = []\n",
    "for i, item in df_test.iterrows():\n",
    "    test_pmid = item['pmid']\n",
    "    control_pmid = control_dict[test_pmid]\n",
    "    D_test_i = list(df_pubmed[df_pubmed['pmid'] == test_pmid]['mED_rel'].values)\n",
    "    D_control_i = list(df_pubmed[df_pubmed.pmid.isin(control_pmid)]['mED_rel'].values)\n",
    "    if D_test_i[0] is not None and len(D_control_i) >= 5:\n",
    "        D_test.append(D_test_i[0])\n",
    "        D_control_i_mean = np.mean(D_control_i)\n",
    "        D_control.append(D_control_i_mean)        \n",
    "\n",
    "print(len(D_control))\n",
    "print(len(D_test))\n",
    "print(np.mean(D_control))\n",
    "print(np.mean(D_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "print(stats.levene(D_test, D_control))    ### p >> 0.05，homogeneity of variances，equal_var = True; otherwise, heterocedasticity, equal_var = False\n",
    "print(stats.ttest_ind(D_test, D_control, equal_var = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prize papers\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "with open('control_groups/control_pair_dict_year_authors_and_cits_1to5_prize.dat', 'rb') as handle:\n",
    "    control_dict2 = pickle.load(handle)\n",
    "print(len(control_dict2.keys()))\n",
    "\n",
    "df_pubmed = pd.read_csv(r'data/pubmed_mED(rel).csv', header = 0)\n",
    "df_test = df_pubmed[df_pubmed.pmid.isin(list(control_dict2.keys()))]\n",
    "\n",
    "D_test2 = []\n",
    "D_control2 = []\n",
    "for i, item in df_test.iterrows():\n",
    "    test_pmid = item['pmid']\n",
    "    control_pmid = control_dict2[test_pmid]\n",
    "    D_test_i = list(df_pubmed[df_pubmed['pmid'] == test_pmid]['mED_rel'].values)\n",
    "    D_control_i = list(df_pubmed[df_pubmed.pmid.isin(control_pmid)]['mED_rel'].values)\n",
    "    if D_test_i[0] is not None and len(D_control_i) >= 5:\n",
    "        D_test2.append(D_test_i[0])\n",
    "        D_control_i_mean = np.mean(D_control_i)\n",
    "        D_control2.append(D_control_i_mean)        \n",
    "\n",
    "print(len(D_control2))\n",
    "print(len(D_test2))\n",
    "print(np.mean(D_control2))\n",
    "print(np.mean(D_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "print(stats.levene(D_test2, D_control2)) ### p >> 0.05，homogeneity of variances，equal_var = True; otherwise, heterocedasticity, equal_var = False\n",
    "print(stats.ttest_ind(D_test2, D_control2, equal_var = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highly cited papers\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "with open('control_groups/control_pair_dict_year_authors_and_1to5_highly_cited.dat', 'rb') as handle:\n",
    "    control_dict3 = pickle.load(handle)\n",
    "print(len(control_dict3.keys()))\n",
    "\n",
    "df_pubmed = pd.read_csv(r'data/pubmed_mED(rel).csv', header = 0)\n",
    "df_test = df_pubmed[df_pubmed.pmid.isin(list(control_dict3.keys()))]\n",
    "\n",
    "D_test3 = []\n",
    "D_control3 = []\n",
    "for i, item in df_test.iterrows():\n",
    "    test_pmid = item['pmid']\n",
    "    control_pmid = control_dict3[test_pmid]\n",
    "    D_test_i = list(df_pubmed[df_pubmed['pmid'] == test_pmid]['mED_rel'].values)\n",
    "    D_control_i = list(df_pubmed[df_pubmed.pmid.isin(control_pmid)]['mED_rel'].values)\n",
    "    if D_test_i[0] is not None and len(D_control_i) >= 5:\n",
    "        D_test3.append(D_test_i[0])\n",
    "        D_control_i_mean = np.mean(D_control_i)\n",
    "        D_control3.append(D_control_i_mean)        \n",
    "\n",
    "print(len(D_control3))\n",
    "print(len(D_test3))\n",
    "print(np.mean(D_control3))\n",
    "print(np.mean(D_test3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "print(stats.levene(D_test3, D_control3)) ### p >> 0.05，homogeneity of variances，equal_var = True; otherwise, heterocedasticity, equal_var = False\n",
    "print(stats.ttest_ind(D_test3, D_control3, equal_var = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faculty papers\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "with open('control_groups/control_pair_dict_year_authors_and_cits_1to5_faculty.dat', 'rb') as handle:\n",
    "    control_dict4 = pickle.load(handle)\n",
    "print(len(control_dict4.keys()))\n",
    "\n",
    "df_pubmed = pd.read_csv(r'data/pubmed_mED(rel).csv', header = 0)\n",
    "df_test = df_pubmed[df_pubmed.pmid.isin(list(control_dict4.keys()))]\n",
    "\n",
    "D_test4 = []\n",
    "D_control4 = []\n",
    "for i, item in df_test.iterrows():\n",
    "    test_pmid = item['pmid']\n",
    "    control_pmid = control_dict4[test_pmid]\n",
    "    D_test_i = list(df_pubmed[df_pubmed['pmid'] == test_pmid]['mED_rel'].values)\n",
    "    D_control_i = list(df_pubmed[df_pubmed.pmid.isin(control_pmid)]['mED_rel'].values)\n",
    "    if D_test_i[0] is not None and len(D_control_i) >= 5:\n",
    "        D_test4.append(D_test_i[0])\n",
    "        D_control_i_mean = np.mean(D_control_i)\n",
    "        D_control4.append(D_control_i_mean)        \n",
    "\n",
    "print(len(D_control4))\n",
    "print(len(D_test4))\n",
    "print(np.mean(D_control4))\n",
    "print(np.mean(D_test4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "print(stats.levene(D_test4, D_control4))   ### p >> 0.05，homogeneity of variances，equal_var = True; otherwise, heterocedasticity, equal_var = False\n",
    "print(stats.ttest_ind(D_test4, D_control4, equal_var = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "fig, ax = plt.subplots(2,2,figsize = (12,10))\n",
    "\n",
    "sns.distplot(D_test,kde = True, ax = ax[0,0],color = '#9AC9DB')\n",
    "sns.distplot(D_control,kde = True,ax = ax[0,0],color ='#F8AC8C')\n",
    "ax[0,0].axvline(np.mean(D_test),color = '#9AC9DB', linestyle = 'dashed', linewidth = 1.5)\n",
    "ax[0,0].axvline(np.mean(D_control),color = '#F8AC8C', linestyle = 'dashed', linewidth = 1.5)\n",
    "ax[0,0].set_xlabel('disruption value', fontsize = 10)\n",
    "# ax[0,0].set_xlim(-0.02, 0.02)\n",
    "ax[0,0].legend(['test group', 'control group'], loc = 'upper right')\n",
    "ax[0,0].text(0.55, 0.75, 'T-test, p-value = 2.369e-05', transform = ax[0,0].transAxes, fontdict = {'size': '10', 'color': 'black'})\n",
    "ax[0,0].spines['bottom'].set_linewidth(0.5)\n",
    "ax[0,0].spines['bottom'].set_color('gray')\n",
    "ax[0,0].spines['left'].set_linewidth(0.5)\n",
    "ax[0,0].spines['left'].set_color('gray')\n",
    "ax[0,0].spines['top'].set_linewidth(0.5)\n",
    "ax[0,0].spines['top'].set_color('gray')\n",
    "ax[0,0].spines['right'].set_linewidth(0.5)\n",
    "ax[0,0].spines['right'].set_color('gray')\n",
    "# ax[0,0].spines['top'].set_visible(False)\n",
    "# ax[0,0].spines['right'].set_visible(False)\n",
    "ax[0,0].set_title('Science breakthrough papers', fontsize = 12, loc = 'center')\n",
    "\n",
    "sns.distplot(D_test2,kde = True, ax = ax[0,1],color = '#9AC9DB')\n",
    "sns.distplot(D_control2,kde = True,ax = ax[0,1],color ='#F8AC8C')\n",
    "ax[0,1].axvline(np.mean(D_test2),color = '#9AC9DB', linestyle = 'dashed', linewidth = 1.5)\n",
    "ax[0,1].axvline(np.mean(D_control2),color = '#F8AC8C', linestyle = 'dashed', linewidth = 1.5)\n",
    "ax[0,1].set_xlabel('disruption value', fontsize = 10)\n",
    "# ax[0,1].set_xlim(-0.02, 0.02)\n",
    "ax[0,1].legend(['test group', 'control group'], loc = 'upper right')\n",
    "ax[0,1].text(0.6, 0.75, 'T-test, p-value = 0.480', transform = ax[0,1].transAxes, fontdict = {'size': '10', 'color': 'black'})\n",
    "ax[0,1].spines['bottom'].set_linewidth(0.5)\n",
    "ax[0,1].spines['bottom'].set_color('gray')\n",
    "ax[0,1].spines['left'].set_linewidth(0.5)\n",
    "ax[0,1].spines['left'].set_color('gray')\n",
    "ax[0,1].spines['top'].set_linewidth(0.5)\n",
    "ax[0,1].spines['top'].set_color('gray')\n",
    "ax[0,1].spines['right'].set_linewidth(0.5)\n",
    "ax[0,1].spines['right'].set_color('gray')\n",
    "# ax[0,1].spines['top'].set_visible(False)\n",
    "# ax[0,1].spines['right'].set_visible(False)\n",
    "ax[0,1].set_title('Prize papers', fontsize = 12, loc = 'center')\n",
    "\n",
    "sns.distplot(D_test3,kde = True, ax = ax[1,0],color = '#9AC9DB')\n",
    "sns.distplot(D_control3,kde = True,ax = ax[1,0],color ='#F8AC8C')\n",
    "ax[1,0].axvline(np.mean(D_test3),color = '#9AC9DB', linestyle = 'dashed', linewidth = 1.5)\n",
    "ax[1,0].axvline(np.mean(D_control3),color = '#F8AC8C', linestyle = 'dashed', linewidth = 1.5)\n",
    "ax[1,0].set_xlabel('disruption value', fontsize = 10)\n",
    "ax[1,0].set_xlim(-0.02, 0.02)\n",
    "ax[1,0].legend(['test group', 'control group'], loc = 'upper left')\n",
    "ax[1,0].text(0.02, 0.75, 'T-test, p-value = 3.415e-66', transform = ax[1,0].transAxes, fontdict = {'size': '10', 'color': 'black'})\n",
    "ax[1,0].spines['bottom'].set_linewidth(0.5)\n",
    "ax[1,0].spines['bottom'].set_color('gray')\n",
    "ax[1,0].spines['left'].set_linewidth(0.5)\n",
    "ax[1,0].spines['left'].set_color('gray')\n",
    "ax[1,0].spines['top'].set_linewidth(0.5)\n",
    "ax[1,0].spines['top'].set_color('gray')\n",
    "ax[1,0].spines['right'].set_linewidth(0.5)\n",
    "ax[1,0].spines['right'].set_color('gray')\n",
    "# ax[1,0].spines['top'].set_visible(False)\n",
    "# ax[1,0].spines['right'].set_visible(False)\n",
    "ax[1,0].set_title('Highly cited papers', fontsize = 12, loc = 'center')\n",
    "\n",
    "axin = ax[1,0].inset_axes([0.12, 0.22, 0.3, 0.35])\n",
    "sns.distplot(D_test3,kde = True, ax = axin,color = '#9AC9DB')\n",
    "axin.set_xlim(-0.2, 0.2)\n",
    "# axin.set_ylim(0, 12)\n",
    "axin.set(ylabel = None)\n",
    "axin.spines['bottom'].set_linewidth(0.5)\n",
    "axin.spines['bottom'].set_color('gray')\n",
    "axin.spines['left'].set_linewidth(0.5)\n",
    "axin.spines['left'].set_color('gray')\n",
    "axin.spines['top'].set_linewidth(0.5)\n",
    "axin.spines['top'].set_color('gray')\n",
    "axin.spines['right'].set_linewidth(0.5)\n",
    "axin.spines['right'].set_color('gray')\n",
    "\n",
    "sns.distplot(D_test4,kde = True, ax = ax[1,1],color = '#9AC9DB')\n",
    "sns.distplot(D_control4,kde = True,ax = ax[1,1],color ='#F8AC8C')\n",
    "ax[1,1].axvline(np.mean(D_test4),color = '#9AC9DB', linestyle = 'dashed', linewidth = 1.5)\n",
    "ax[1,1].axvline(np.mean(D_control4),color = '#F8AC8C', linestyle = 'dashed', linewidth = 1.5)\n",
    "ax[1,1].set_xlabel('disruption value', fontsize = 10)\n",
    "# ax[1,1].set_xlim(-0.02, 0.02)\n",
    "ax[1,1].legend(['test group', 'control group'], loc = 'upper right')\n",
    "ax[1,1].text(0.55, 0.75, 'T-test, p-value = 1.574e-59', transform = ax[1,1].transAxes, fontdict = {'size': '10', 'color': 'black'})\n",
    "ax[1,1].spines['bottom'].set_linewidth(0.5)\n",
    "ax[1,1].spines['bottom'].set_color('gray')\n",
    "ax[1,1].spines['left'].set_linewidth(0.5)\n",
    "ax[1,1].spines['left'].set_color('gray')\n",
    "ax[1,1].spines['top'].set_linewidth(0.5)\n",
    "ax[1,1].spines['top'].set_color('gray')\n",
    "ax[1,1].spines['right'].set_linewidth(0.5)\n",
    "ax[1,1].spines['right'].set_color('gray')\n",
    "# ax[1,1].spines['top'].set_visible(False)\n",
    "# ax[1,1].spines['right'].set_visible(False)\n",
    "ax[1,1].set_title('Faculty Opinions papers', fontsize = 12, loc = 'center')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
